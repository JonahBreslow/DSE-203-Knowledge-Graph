{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1e653994-873a-4eaf-9cec-d416d7348648",
   "metadata": {},
   "source": [
    "# Dedupe openfda versus medicare part D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "97ddaeab-1c0b-4f5e-84aa-a4b5d4f8f0ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/python\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "This code demonstrates how to use RecordLink with two comma separated\n",
    "values (CSV) files. We have listings of products from two different\n",
    "online stores. The task is to link products between the datasets.\n",
    "\n",
    "The output will be a CSV with our linkded results.\n",
    "\n",
    "\"\"\"\n",
    "import os\n",
    "import csv\n",
    "import re\n",
    "import logging\n",
    "import optparse\n",
    "import pandas as pd\n",
    "\n",
    "import dedupe\n",
    "from unidecode import unidecode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e9fb43f4-af4d-43bb-b0e4-477bb42e4854",
   "metadata": {},
   "outputs": [],
   "source": [
    "sunshine_manuf = pd.read_csv('../Data/Outputs_Cleanup/Sunshine/pharmCo_info.csv')\n",
    "df = sunshine_manuf[['Applicable_Manufacturer_or_Applicable_GPO_Making_Payment_Name']]\n",
    "df.columns = ['manufacturer_name']\n",
    "df.to_csv('../Data/Outputs_Cleanup/Sunshine/pharmCo_manufacturer_dedupe_input.csv', index=False)\n",
    "#df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aab214b3-2af5-4ace-b4ca-0be915049514",
   "metadata": {},
   "outputs": [],
   "source": [
    "openfda_manuf = pd.read_csv('../Data/Outputs_Cleanup/FDA/openfda_manufacturer_deduplicated_single_manuf.csv')#df = openfda_manuf[['manufacturer_name']]\n",
    "df = openfda_manuf[['manufacturer_name']]\n",
    "#df.columns = ['manufacturer_name']\n",
    "df.to_csv('../Data/Outputs_Cleanup/FDA/openfda_manufacturer_dedupe_input.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a8443f31-5f80-46ae-be2f-09310f14ca4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preProcess(column):\n",
    "    \"\"\"\n",
    "    Do a little bit of data cleaning with the help of Unidecode and Regex.\n",
    "    Things like casing, extra spaces, quotes and new lines can be ignored.\n",
    "    \"\"\"\n",
    "\n",
    "    column = unidecode(column)\n",
    "    column = re.sub('\\n', ' ', column)\n",
    "    column = re.sub('-', '', column)\n",
    "    column = re.sub('/', ' ', column)\n",
    "    column = re.sub(\"'\", '', column)\n",
    "    column = re.sub(\",\", '', column)\n",
    "    column = re.sub(\":\", ' ', column)\n",
    "    column = re.sub('  +', ' ', column)\n",
    "    column = column.strip().strip('\"').strip(\"'\").lower().strip()\n",
    "    if not column:\n",
    "        column = None\n",
    "    return column\n",
    "\n",
    "\n",
    "def readData(filename):\n",
    "    \"\"\"\n",
    "    Read in our data from a CSV file and create a dictionary of records,\n",
    "    where the key is a unique record ID.\n",
    "    \"\"\"\n",
    "\n",
    "    data_d = {}\n",
    "\n",
    "    with open(filename) as f:\n",
    "        reader = csv.DictReader(f)\n",
    "        for i, row in enumerate(reader):\n",
    "            clean_row = dict([(k, preProcess(v)) for (k, v) in row.items()])\n",
    "            data_d[filename + str(i)] = dict(clean_row)\n",
    "\n",
    "    return data_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8a488e6d-083f-4542-8c98-fd2e4aa0c27a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Do you want to add on to your training (y/n). If you wanted to start over, delete your .json file y\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:dedupe.api:reading training from file\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing data ...\n",
      "reading labeled examples from  ../Data/Outputs_Cleanup/Manufacturer_entity_matching/data_matching_training.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:dedupe.canopy_index:Removing stop word  c\n",
      "INFO:dedupe.canopy_index:Removing stop word ac\n",
      "INFO:dedupe.canopy_index:Removing stop word ar\n",
      "INFO:dedupe.canopy_index:Removing stop word ca\n",
      "INFO:dedupe.canopy_index:Removing stop word co\n",
      "INFO:dedupe.canopy_index:Removing stop word ha\n",
      "INFO:dedupe.canopy_index:Removing stop word in\n",
      "INFO:dedupe.canopy_index:Removing stop word l \n",
      "INFO:dedupe.canopy_index:Removing stop word ma\n",
      "INFO:dedupe.canopy_index:Removing stop word on\n",
      "INFO:dedupe.canopy_index:Removing stop word ra\n",
      "INFO:dedupe.canopy_index:Removing stop word rm\n",
      "INFO:dedupe.canopy_index:Removing stop word ti\n",
      "INFO:dedupe.canopy_index:Removing stop word  l\n",
      "INFO:dedupe.canopy_index:Removing stop word an\n",
      "INFO:dedupe.canopy_index:Removing stop word ch\n",
      "INFO:dedupe.canopy_index:Removing stop word en\n",
      "INFO:dedupe.canopy_index:Removing stop word lt\n",
      "INFO:dedupe.canopy_index:Removing stop word n \n",
      "INFO:dedupe.canopy_index:Removing stop word nt\n",
      "INFO:dedupe.canopy_index:Removing stop word o \n",
      "INFO:dedupe.canopy_index:Removing stop word ol\n",
      "INFO:dedupe.canopy_index:Removing stop word ro\n",
      "INFO:dedupe.canopy_index:Removing stop word td\n",
      "INFO:dedupe.canopy_index:Removing stop word y \n",
      "INFO:dedupe.canopy_index:Removing stop word  i\n",
      "INFO:dedupe.canopy_index:Removing stop word a \n",
      "INFO:dedupe.canopy_index:Removing stop word e \n",
      "INFO:dedupe.canopy_index:Removing stop word nc\n",
      "INFO:dedupe.canopy_index:Removing stop word s \n",
      "INFO:dedupe.canopy_index:Removing stop word re\n",
      "INFO:dedupe.canopy_index:Removing stop word ed\n",
      "INFO:dedupe.canopy_index:Removing stop word li\n",
      "INFO:dedupe.canopy_index:Removing stop word lc\n",
      "INFO:dedupe.canopy_index:Removing stop word he\n",
      "INFO:dedupe.canopy_index:Removing stop word sa\n",
      "INFO:dedupe.canopy_index:Removing stop word di\n",
      "INFO:dedupe.canopy_index:Removing stop word st\n",
      "INFO:dedupe.canopy_index:Removing stop word co\n",
      "INFO:dedupe.canopy_index:Removing stop word inc\n",
      "INFO:dedupe.canopy_index:Removing stop word llc\n",
      "INFO:dedupe.canopy_index:Removing stop word  p\n",
      "INFO:dedupe.canopy_index:Removing stop word at\n",
      "INFO:dedupe.canopy_index:Removing stop word ic\n",
      "INFO:dedupe.canopy_index:Removing stop word io\n",
      "INFO:dedupe.canopy_index:Removing stop word ng\n",
      "INFO:dedupe.canopy_index:Removing stop word ri\n",
      "INFO:dedupe.canopy_index:Removing stop word ut\n",
      "INFO:dedupe.canopy_index:Removing stop word  s\n",
      "INFO:dedupe.canopy_index:Removing stop word er\n",
      "INFO:dedupe.canopy_index:Removing stop word me\n",
      "INFO:dedupe.canopy_index:Removing stop word te\n",
      "INFO:dedupe.canopy_index:Removing stop word  d\n",
      "INFO:dedupe.canopy_index:Removing stop word es\n",
      "INFO:dedupe.canopy_index:Removing stop word t \n",
      "INFO:dedupe.canopy_index:Removing stop word ltd\n",
      "INFO:dedupe.training:Final predicate set:\n",
      "INFO:dedupe.training:TfidfNGramSearchPredicate: (0.8, manufacturer_name)\n",
      "INFO:dedupe.training:Final predicate set:\n",
      "INFO:dedupe.training:SimplePredicate: (sameSevenCharStartPredicate, manufacturer_name)\n",
      "INFO:dedupe.training:LevenshteinSearchPredicate: (1, manufacturer_name)\n",
      "manufacturer_name : mitsui chemicals inc\n",
      "\n",
      "manufacturer_name : mit\n",
      "\n",
      "15/10 positive, 13/10 negative\n",
      "Do these records refer to the same thing?\n",
      "(y)es / (n)o / (u)nsure / (f)inished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting active labeling...\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " n\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "manufacturer_name : owp pharmaceuticals inc\n",
      "\n",
      "manufacturer_name : oba pharmaceuticals inc\n",
      "\n",
      "15/10 positive, 14/10 negative\n",
      "Do these records refer to the same thing?\n",
      "(y)es / (n)o / (u)nsure / (f)inished / (p)revious\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " n\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "manufacturer_name : adare pharmaceuticals inc\n",
      "\n",
      "manufacturer_name : aace pharmaceuticals inc\n",
      "\n",
      "15/10 positive, 15/10 negative\n",
      "Do these records refer to the same thing?\n",
      "(y)es / (n)o / (u)nsure / (f)inished / (p)revious\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " n\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "manufacturer_name : taro pharmaceuticals usa inc\n",
      "\n",
      "manufacturer_name : taro pharmaceuticals inc\n",
      "\n",
      "15/10 positive, 16/10 negative\n",
      "Do these records refer to the same thing?\n",
      "(y)es / (n)o / (u)nsure / (f)inished / (p)revious\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " y\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "manufacturer_name : salix pharmaceuticals a division of bausch health us llc\n",
      "\n",
      "manufacturer_name : salix pharmaceuticals inc\n",
      "\n",
      "16/10 positive, 16/10 negative\n",
      "Do these records refer to the same thing?\n",
      "(y)es / (n)o / (u)nsure / (f)inished / (p)revious\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " y\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "manufacturer_name : glaxosmithkline llc\n",
      "\n",
      "manufacturer_name : glaxosmithkline consumer healthcare holdings us llc\n",
      "\n",
      "17/10 positive, 16/10 negative\n",
      "Do these records refer to the same thing?\n",
      "(y)es / (n)o / (u)nsure / (f)inished / (p)revious\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " y\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "manufacturer_name : takeda pharmaceuticals usa inc\n",
      "\n",
      "manufacturer_name : teva pharmaceuticals usa inc\n",
      "\n",
      "18/10 positive, 16/10 negative\n",
      "Do these records refer to the same thing?\n",
      "(y)es / (n)o / (u)nsure / (f)inished / (p)revious\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " n\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "manufacturer_name : acelrx pharmaceuticals inc\n",
      "\n",
      "manufacturer_name : scilex pharmaceuticals inc\n",
      "\n",
      "18/10 positive, 17/10 negative\n",
      "Do these records refer to the same thing?\n",
      "(y)es / (n)o / (u)nsure / (f)inished / (p)revious\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " n\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "manufacturer_name : scilex pharmaceuticals inc\n",
      "\n",
      "manufacturer_name : marlex pharmaceuticals inc\n",
      "\n",
      "18/10 positive, 18/10 negative\n",
      "Do these records refer to the same thing?\n",
      "(y)es / (n)o / (u)nsure / (f)inished / (p)revious\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " n\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "manufacturer_name : btg international canada inc\n",
      "\n",
      "manufacturer_name : btg international inc\n",
      "\n",
      "18/10 positive, 19/10 negative\n",
      "Do these records refer to the same thing?\n",
      "(y)es / (n)o / (u)nsure / (f)inished / (p)revious\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " n\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "manufacturer_name : hufriedy mfg co llc\n",
      "\n",
      "manufacturer_name : hufriedy mfg co inc\n",
      "\n",
      "18/10 positive, 20/10 negative\n",
      "Do these records refer to the same thing?\n",
      "(y)es / (n)o / (u)nsure / (f)inished / (p)revious\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " y\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "manufacturer_name : provisio medical\n",
      "\n",
      "manufacturer_name : provision medical products\n",
      "\n",
      "19/10 positive, 20/10 negative\n",
      "Do these records refer to the same thing?\n",
      "(y)es / (n)o / (u)nsure / (f)inished / (p)revious\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " n\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "manufacturer_name : emergent biosolutions inc\n",
      "\n",
      "manufacturer_name : emergent biosolutions canada inc\n",
      "\n",
      "19/10 positive, 21/10 negative\n",
      "Do these records refer to the same thing?\n",
      "(y)es / (n)o / (u)nsure / (f)inished / (p)revious\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " y\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "manufacturer_name : neos therapeutics lp\n",
      "\n",
      "manufacturer_name : neos therapeutics brands llc\n",
      "\n",
      "20/10 positive, 21/10 negative\n",
      "Do these records refer to the same thing?\n",
      "(y)es / (n)o / (u)nsure / (f)inished / (p)revious\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " y\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "manufacturer_name : smithnephew inc\n",
      "\n",
      "manufacturer_name : smith nephew inc\n",
      "\n",
      "21/10 positive, 21/10 negative\n",
      "Do these records refer to the same thing?\n",
      "(y)es / (n)o / (u)nsure / (f)inished / (p)revious\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " y\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "manufacturer_name : endo pharmaceuticals inc\n",
      "\n",
      "manufacturer_name : endo pharmaceuticals solutions inc\n",
      "\n",
      "22/10 positive, 21/10 negative\n",
      "Do these records refer to the same thing?\n",
      "(y)es / (n)o / (u)nsure / (f)inished / (p)revious\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " y\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "manufacturer_name : cycle pharmaceuticals inc\n",
      "\n",
      "manufacturer_name : cycle pharmaceuticals ltduk\n",
      "\n",
      "23/10 positive, 21/10 negative\n",
      "Do these records refer to the same thing?\n",
      "(y)es / (n)o / (u)nsure / (f)inished / (p)revious\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " y\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "manufacturer_name : alexion pharmaceuticals inc\n",
      "\n",
      "manufacturer_name : lexicon pharmaceuticals inc\n",
      "\n",
      "24/10 positive, 21/10 negative\n",
      "Do these records refer to the same thing?\n",
      "(y)es / (n)o / (u)nsure / (f)inished / (p)revious\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " n\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "manufacturer_name : jazz pharmaceuticals inc\n",
      "\n",
      "manufacturer_name : aace pharmaceuticals inc\n",
      "\n",
      "24/10 positive, 22/10 negative\n",
      "Do these records refer to the same thing?\n",
      "(y)es / (n)o / (u)nsure / (f)inished / (p)revious\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " n\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "manufacturer_name : jubilant draximage inc\n",
      "\n",
      "manufacturer_name : jubilant draximage usa inc\n",
      "\n",
      "24/10 positive, 23/10 negative\n",
      "Do these records refer to the same thing?\n",
      "(y)es / (n)o / (u)nsure / (f)inished / (p)revious\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " y\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "manufacturer_name : horizon therapeutics plc\n",
      "\n",
      "manufacturer_name : horizon therapeutics usa inc\n",
      "\n",
      "25/10 positive, 23/10 negative\n",
      "Do these records refer to the same thing?\n",
      "(y)es / (n)o / (u)nsure / (f)inished / (p)revious\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " f\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Finished labeling\n",
      "INFO:rlr.crossvalidation:using cross validation to find optimum alpha...\n",
      "INFO:rlr.crossvalidation:optimum alpha: 0.000010, score 0.1873522082478936\n",
      "INFO:dedupe.training:Final predicate set:\n",
      "INFO:dedupe.training:(SimplePredicate: (sameSevenCharStartPredicate, manufacturer_name), TfidfNGramSearchPredicate: (0.2, manufacturer_name))\n",
      "INFO:dedupe.training:(SimplePredicate: (sameFiveCharStartPredicate, manufacturer_name), SimplePredicate: (commonTwoTokens, manufacturer_name))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clustering...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:dedupe.canopy_index:Removing stop word  c\n",
      "INFO:dedupe.canopy_index:Removing stop word ac\n",
      "INFO:dedupe.canopy_index:Removing stop word ar\n",
      "INFO:dedupe.canopy_index:Removing stop word ca\n",
      "INFO:dedupe.canopy_index:Removing stop word co\n",
      "INFO:dedupe.canopy_index:Removing stop word ha\n",
      "INFO:dedupe.canopy_index:Removing stop word in\n",
      "INFO:dedupe.canopy_index:Removing stop word l \n",
      "INFO:dedupe.canopy_index:Removing stop word ma\n",
      "INFO:dedupe.canopy_index:Removing stop word on\n",
      "INFO:dedupe.canopy_index:Removing stop word ra\n",
      "INFO:dedupe.canopy_index:Removing stop word rm\n",
      "INFO:dedupe.canopy_index:Removing stop word ti\n",
      "INFO:dedupe.canopy_index:Removing stop word  l\n",
      "INFO:dedupe.canopy_index:Removing stop word an\n",
      "INFO:dedupe.canopy_index:Removing stop word ch\n",
      "INFO:dedupe.canopy_index:Removing stop word en\n",
      "INFO:dedupe.canopy_index:Removing stop word lt\n",
      "INFO:dedupe.canopy_index:Removing stop word n \n",
      "INFO:dedupe.canopy_index:Removing stop word nt\n",
      "INFO:dedupe.canopy_index:Removing stop word o \n",
      "INFO:dedupe.canopy_index:Removing stop word ol\n",
      "INFO:dedupe.canopy_index:Removing stop word ro\n",
      "INFO:dedupe.canopy_index:Removing stop word td\n",
      "INFO:dedupe.canopy_index:Removing stop word y \n",
      "INFO:dedupe.canopy_index:Removing stop word  i\n",
      "INFO:dedupe.canopy_index:Removing stop word a \n",
      "INFO:dedupe.canopy_index:Removing stop word e \n",
      "INFO:dedupe.canopy_index:Removing stop word nc\n",
      "INFO:dedupe.canopy_index:Removing stop word s \n",
      "INFO:dedupe.canopy_index:Removing stop word re\n",
      "INFO:dedupe.canopy_index:Removing stop word ed\n",
      "INFO:dedupe.canopy_index:Removing stop word li\n",
      "INFO:dedupe.canopy_index:Removing stop word lc\n",
      "INFO:dedupe.canopy_index:Removing stop word he\n",
      "INFO:dedupe.canopy_index:Removing stop word sa\n",
      "INFO:dedupe.canopy_index:Removing stop word di\n",
      "INFO:dedupe.canopy_index:Removing stop word st\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# duplicate sets 389\n"
     ]
    }
   ],
   "source": [
    " # ## Setup\n",
    "output_file = '../Data/Outputs_Cleanup/Manufacturer_entity_matching/data_matching_output.csv'\n",
    "settings_file = '../Data/Outputs_Cleanup/Manufacturer_entity_matching/data_matching_learned_settings'\n",
    "training_file = '../Data/Outputs_Cleanup/Manufacturer_entity_matching/data_matching_training.json'\n",
    "    \n",
    "retrain = input('Do you want to add on to your training (y/n). If you wanted to start over, delete your .json file')\n",
    "isretrain = True if retrain == 'y' else False\n",
    "\n",
    "if isretrain == True:\n",
    "    try:\n",
    "        os.remove(settings_file)\n",
    "    except:\n",
    "        print('Your settings file appears to not have existed.')\n",
    "\n",
    "left_file = '../Data/Outputs_Cleanup/Sunshine/pharmCo_manufacturer_dedupe_input.csv'\n",
    "right_file = '../Data/Outputs_Cleanup/FDA/openfda_manufacturer_dedupe_input.csv'\n",
    "\n",
    "print('importing data ...')\n",
    "data_1 = readData(left_file)\n",
    "data_2 = readData(right_file)\n",
    "\n",
    "def descriptions():\n",
    "    for dataset in (data_1, data_2):\n",
    "        for record in dataset.values():\n",
    "            yield record['description']\n",
    "\n",
    "# ## Training\n",
    "\n",
    "if os.path.exists(settings_file):\n",
    "    print('reading from', settings_file)\n",
    "    with open(settings_file, 'rb') as sf:\n",
    "        linker = dedupe.StaticRecordLink(sf)\n",
    "\n",
    "else:\n",
    "    # Define the fields the linker will pay attention to\n",
    "    #\n",
    "    # Notice how we are telling the linker to use a custom field comparator\n",
    "    # for the 'price' field.\n",
    "    fields = [\n",
    "        {'field': 'manufacturer_name', 'type': 'String'},\n",
    "        #{'field': 'title', 'type': 'Text', 'corpus': descriptions()},\n",
    "        #{'field': 'description', 'type': 'Text',\n",
    "        # 'has missing': True, 'corpus': descriptions()},\n",
    "        #{'field': 'price', 'type': 'Price', 'has missing': True}\n",
    "    ]\n",
    "\n",
    "    # Create a new linker object and pass our data model to it.\n",
    "    linker = dedupe.RecordLink(fields)\n",
    "\n",
    "    # If we have training data saved from a previous run of linker,\n",
    "    # look for it an load it in.\n",
    "    # __Note:__ if you want to train from scratch, delete the training_file\n",
    "    if os.path.exists(training_file):\n",
    "        print('reading labeled examples from ', training_file)\n",
    "        with open(training_file) as tf:\n",
    "            linker.prepare_training(data_1,\n",
    "                                    data_2,\n",
    "                                    training_file=tf,\n",
    "                                    sample_size=15000)\n",
    "    else:\n",
    "        linker.prepare_training(data_1, data_2, sample_size=15000)\n",
    "\n",
    "    # ## Active learning\n",
    "    # Dedupe will find the next pair of records\n",
    "    # it is least certain about and ask you to label them as matches\n",
    "    # or not.\n",
    "    # use 'y', 'n' and 'u' keys to flag duplicates\n",
    "    # press 'f' when you are finished\n",
    "    print('starting active labeling...')\n",
    "\n",
    "    dedupe.console_label(linker)\n",
    "\n",
    "    linker.train()\n",
    "\n",
    "    # When finished, save our training away to disk\n",
    "    with open(training_file, 'w') as tf:\n",
    "        linker.write_training(tf)\n",
    "\n",
    "    # Save our weights and predicates to disk.  If the settings file\n",
    "    # exists, we will skip all the training and learning next time we run\n",
    "    # this file.\n",
    "    with open(settings_file, 'wb') as sf:\n",
    "        linker.write_settings(sf)\n",
    "\n",
    "# ## Blocking\n",
    "\n",
    "# ## Clustering\n",
    "\n",
    "# Find the threshold that will maximize a weighted average of our\n",
    "# precision and recall.  When we set the recall weight to 2, we are\n",
    "# saying we care twice as much about recall as we do precision.\n",
    "#\n",
    "# If we had more data, we would not pass in all the blocked data into\n",
    "# this function but a representative sample.\n",
    "\n",
    "print('clustering...')\n",
    "linked_records = linker.join(data_1, data_2, 0.0)\n",
    "\n",
    "print('# duplicate sets', len(linked_records))\n",
    "# ## Writing Results\n",
    "\n",
    "# Write our original data back out to a CSV with a new column called\n",
    "# 'Cluster ID' which indicates which records refer to each other.\n",
    "\n",
    "cluster_membership = {}\n",
    "for cluster_id, (cluster, score) in enumerate(linked_records):\n",
    "    for record_id in cluster:\n",
    "        cluster_membership[record_id] = {'Cluster ID': cluster_id,\n",
    "                                         'Link Score': score}\n",
    "\n",
    "with open(output_file, 'w') as f:\n",
    "\n",
    "    header_unwritten = True\n",
    "\n",
    "    for fileno, filename in enumerate((left_file, right_file)):\n",
    "        with open(filename) as f_input:\n",
    "            reader = csv.DictReader(f_input)\n",
    "\n",
    "            if header_unwritten:\n",
    "\n",
    "                fieldnames = (['Cluster ID', 'Link Score', 'source file'] +\n",
    "                              reader.fieldnames)\n",
    "\n",
    "                writer = csv.DictWriter(f, fieldnames=fieldnames)\n",
    "                writer.writeheader()\n",
    "\n",
    "                header_unwritten = False\n",
    "\n",
    "            for row_id, row in enumerate(reader):\n",
    "\n",
    "                record_id = filename + str(row_id)\n",
    "                cluster_details = cluster_membership.get(record_id, {})\n",
    "                row['source file'] = fileno\n",
    "                row.update(cluster_details)\n",
    "\n",
    "                writer.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7be8112-d233-41ce-9cf6-d7963e00f65a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../Data/Outputs_Cleanup/Manufacturer_entity_matching/data_matching_output.csv')\n",
    "#df.sort_values('Cluster ID')\n",
    "df_fda = df[df['source file'] == 0]\n",
    "df_sunshine = df[df['source file'] == 1]\n",
    "df_fda = df_fda.merge(fda_drugs[['manufacturer_name', 'manuf__id']], how='left', on='brand_name')\n",
    "df_partD = df_partD.merge(medD_drugs[['brand_name', 'MedD_drug_Id']], how='left', on='brand_name')\n",
    "\n",
    "drug_merge = pd.concat([df_fda, df_partD], axis=0).sort_values('Cluster ID')\n",
    "drug_merge['fda_drug_id'] = drug_merge['fda_drug_id'].fillna('[]')\n",
    "drug_merge['MedD_drug_Id'] = drug_merge['MedD_drug_Id'].fillna('[]')\n",
    "drug_merge = drug_merge.groupby('Cluster ID').agg(list)\n",
    "\n",
    "def pick_list(x):\n",
    "    my_pick = None\n",
    "    for each in x:\n",
    "        if each == '[]':\n",
    "            continue\n",
    "        else:\n",
    "            my_pick = each\n",
    "    return my_pick\n",
    "\n",
    "drug_merge['fda_drug_id'] = drug_merge['fda_drug_id'].apply(lambda x: pick_list(x))\n",
    "drug_merge['MedD_drug_Id'] = drug_merge['MedD_drug_Id'].apply(lambda x: pick_list(x))\n",
    "\n",
    "def pick_longest(x):\n",
    "    longest = None\n",
    "    longest_len = 0\n",
    "    for idx, each in enumerate(x):\n",
    "        if idx == 0:\n",
    "            longest = each\n",
    "            longest_len = len(each)\n",
    "            continue\n",
    "        if len(each) > longest_len:\n",
    "            longest = each\n",
    "            longest_len = len(each)  \n",
    "    return longest\n",
    "\n",
    "drug_merge['brand_name'] = drug_merge['brand_name'].apply(lambda x: pick_longest(x))\n",
    "drug_merge = drug_merge[['brand_name', 'fda_drug_id', 'MedD_drug_Id']]\n",
    "drug_merge.to_csv('../../Data/Outputs_Cleanup/FDA_partD_drug_matching/fda_partD_drugs_matched.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
