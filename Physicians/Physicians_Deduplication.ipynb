{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import py_stringmatching as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sunshine = pd.read_csv('../Data/Outputs_Cleanup/Sunshine/physicians_info.csv',dtype=str)\n",
    "sunshine.fillna(value='',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_suffix(lname, suffix):\n",
    "    s = lname + ' ' + suffix\n",
    "    return s.strip()\n",
    "\n",
    "sunshine['Physician_Last_Name'] = sunshine.apply(lambda x: add_suffix(x['Physician_Last_Name'],x['Physician_Name_Suffix']),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sunshine.rename(columns={'Physician_Profile_ID':'id','Physician_First_Name':'fname','Physician_Specialty':'type',\n",
    "                         'Physician_Last_Name':'lname','Recipient_City':'city'},inplace=True)\n",
    "sunshine.drop(columns=['Physician_Middle_Name','Physician_Name_Suffix','Recipient_State','Physician_Primary_Type',\n",
    "                       'Physician_License_State_code1','Physician_License_State_code2','Physician_License_State_code3',\n",
    "                       'Physician_License_State_code4','Physician_License_State_code5','Recipient_Zip_Code'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "part_d = pd.read_csv('../Data/Outputs_Cleanup/Part_d/prescriber_information.csv',dtype=str)\n",
    "part_d.fillna(value='',inplace=True)\n",
    "part_d.rename(columns={'Prscrbr_NPI':'id','Prscrbr_Last_Org_Name':'lname','Prscrbr_First_Name':'fname',\n",
    "                       'Prscrbr_City':'city','Prscrbr_Type':'type'},inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cities were hand deduped during this first run. However, in the future we will need to make a city deduper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sunshine = pd.read_csv('CMS_Sunshine_Physicians.csv',dtype=str)\n",
    "part_d = pd.read_csv('Medicare_PartD_Physicians.csv',dtype=str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processType(x):\n",
    "    s = x.split('|')\n",
    "    return s[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processData(df):\n",
    "    cols = df.columns.to_list()\n",
    "    for col in cols:\n",
    "        df[col] = df[col].astype(str)\n",
    "        df[col] = df[col].apply(lambda x: x.lower().strip())\n",
    "    df['type'] = df['type'].apply(lambda x: processType(x))\n",
    "    df['combined'] = df['fname'] + ' ' + df['lname'] + ' ' + df['city'] + ' ' + df['type']\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sunshine = processData(sunshine)\n",
    "part_d = processData(part_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sunshine_combined_id = sunshine.groupby('combined')['id'].apply(list).reset_index(name='id')\n",
    "part_d_id = part_d.groupby('combined')['id'].apply(list).reset_index(name='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sunshine.drop(columns=['id'],inplace=True)\n",
    "part_d.drop(columns=['id'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sunshine = sunshine.merge(right=sunshine_combined_id,how='left',on='combined')\n",
    "part_d = part_d.merge(right=sunshine_combined_id,how='left',on='combined')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del sunshine_combined_id\n",
    "del part_d_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are duplicates where the same person has two ids in both dataset.<br>\n",
    "The solution is to use the combined column to create a new unique id.<br>\n",
    "Then we will create lookup tables for the new ID and the combined string.<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make the lookup tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sunshine.rename(columns={'id':'Physician_Profile_ID'})[['combined','Physician_Profile_ID']].to_csv('../Data/Physicians_Deduplication/Outputs/CMS_Sunshine_Physicians_NewID.csv',index=False)\n",
    "# part_d.rename(columns={'id':'Prscrbr_NPI'})[['combined','Prscrbr_NPI']].to_csv('../Data/Physicians_Deduplication/Outputs/Medicare_PartD_Physicians_NewID.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sunshine.drop_duplicates(subset='combined',inplace=True)\n",
    "part_d.drop_duplicates(subset='combined',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sunshine_org = sunshine.copy()\n",
    "part_d_org = part_d.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we will do a naive matching. Based on just the 'hashID' column. If there is an exact match we will accept this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_part_d = part_d.merge(right=sunshine,on='combined',how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will remove the matches and set them aside. We will do a more careful inspection of the remaining unmatched ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting aside matches, keeping pairs together\n",
    "matches = merged_part_d.drop(merged_part_d[(merged_part_d['city_x'].isnull()==True) | (merged_part_d['city_y'].isnull()==True)].index)\n",
    "col = matches.columns.to_list()\n",
    "col.remove('combined')\n",
    "matches.drop(columns = col,inplace=True)\n",
    "matches['combined2'] = matches['combined']\n",
    "matches.rename(columns={'combined':'part_d','combined2':'sunshine'},inplace=True)\n",
    "matches.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "part_d.drop(part_d[part_d['combined'].isin(matches['part_d'].to_list())].index,inplace=True)\n",
    "sunshine.drop(sunshine[sunshine['combined'].isin(matches['sunshine'].to_list())].index,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del merged_part_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a new column in sunshine that is the combined column whitespace tokenized    \n",
    "#Create a new column in sunshine that is the combined column unigram tokenized\n",
    "#Create a new column in part_d that is the combined column whitespace tokenized\n",
    "#Create a new column in part_d that is the combined column unigram tokenized\n",
    "whitespace_tokenizer = sm.WhitespaceTokenizer()\n",
    "unigram_tokenizer = sm.QgramTokenizer(qval=2)\n",
    "sunshine['whitespace_tok'] = sunshine['combined'].apply(lambda x: whitespace_tokenizer.tokenize(x))\n",
    "sunshine['Qgram_tok'] = sunshine['combined'].apply(lambda x: unigram_tokenizer.tokenize(x))\n",
    "part_d['whitespace_tok'] = part_d['combined'].apply(lambda x: whitespace_tokenizer.tokenize(x))\n",
    "part_d['Qgram_tok'] = part_d['combined'].apply(lambda x: unigram_tokenizer.tokenize(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We will find matches for the sunshine data in the part_d data\n",
    "#This is because the sunshine data is the smaller set\n",
    "#Here is the procedure:    \n",
    "    #For each row in sunshine\n",
    "        #Filter the city in part_d\n",
    "        #Perform Jaccard on the whitespace token set between the remainder and the row\n",
    "        #Filter out for scores higher than .75\n",
    "        #If the remaining dataframe is 0\n",
    "            #Return None\n",
    "        #Else\n",
    "            #Grab the highest matching one as the match\n",
    "            #Save the match into sunshine_match dataframe and part_d_match dataframe\n",
    "        #Remove the row from both part_d_noDups and sunshine_noDups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_measure = sm.OverlapCoefficient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matched = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_match(sunshine_row):\n",
    "    #filter part_d for the last name:\n",
    "    df_partD = part_d[part_d['lname']==sunshine_row['lname']].copy()\n",
    "    df_partD.drop(df_partD[df_partD['combined'].isin(matched)].index,inplace=True)\n",
    "    if len(df_partD) == 0:\n",
    "        #Return None\n",
    "        return None\n",
    "    #Perform similarity on the token set between the remainder and the row\n",
    "    df_partD['score'] = df_partD['Qgram_tok'].apply(lambda x: sim_measure.get_sim_score(x, sunshine_row['Qgram_tok']))\n",
    "    #Filter out for scores higher than .75\n",
    "    df_partD.drop(df_partD[df_partD['score']<.8].index,inplace=True)\n",
    "    #If the remaining dataframe is 0\n",
    "    if len(df_partD) == 0:\n",
    "        #Return None\n",
    "        return None\n",
    "    #Else if the remaining dataframe is 1\n",
    "    elif len(df_partD) == 1:\n",
    "        #Return the remaining row's hash_id\n",
    "        match = df_partD.iloc[0]['combined']\n",
    "        matched.append(match)\n",
    "        return match\n",
    "    else:\n",
    "        #Sort the remaining rows by score\n",
    "        df_partD.sort_values(by=['score'],axis=0,ascending=False,ignore_index=True,inplace=True)\n",
    "        #Return the highest one\n",
    "        match = df_partD.iloc[0]['combined']\n",
    "        matched.append(match)\n",
    "        return match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "tqdm.pandas(desc=\"Progress\")\n",
    "sunshine['match'] = sunshine.progress_apply(lambda x: find_match(x),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "other_matches = sunshine[sunshine['match'].isnull()==False][['match','combined']].copy()\n",
    "other_matches.rename(columns={'match':'part_d','combined':'sunshine'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches = pd.concat([matches,other_matches],ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "part_d.drop(part_d[part_d['combined'].isin(matches['part_d'].to_list())].index,inplace=True)\n",
    "sunshine.drop(sunshine[sunshine['combined'].isin(matches['sunshine'].to_list())].index,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sunshine[['id','fname','lname','type','city']].to_csv('../Data/Physicians_Deduplication/Outputs/CMS_Sunshine_Physicians_no_matches.csv',index=False)\n",
    "part_d[['id','fname','lname','type','city']].to_csv('../Data/Physicians_Deduplication/Outputs/Medicare_PartD_Physicians_no_matches.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches.to_csv('../Data/Physicians_Deduplication/Outputs/Physician_Matches.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sunshine.drop(columns = ['whitespace_tok','Qgram_tok','match'],inplace=True)\n",
    "part_d.drop(columns = ['whitespace_tok','Qgram_tok'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches.rename(columns={'part_d':'id'},inplace=True)\n",
    "matches = matches.merge(right = part_d_org,how='left',left_on='id',right_on='combined')\n",
    "matches.drop(columns=['sunshine','combined'],inplace=True)\n",
    "matches.rename(columns={'id_x':'combined','id_y':'Prscrbr_NPI'},inplace=True)\n",
    "matches = matches.merge(right = sunshine_org[['combined','id']],how='left',on='combined')\n",
    "matches.rename(columns={'id':'Physician_Profile_ID'},inplace=True)\n",
    "matches = matches[['combined','Prscrbr_NPI','Physician_Profile_ID','fname','lname','type','city']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sunshine.rename(columns={'id':'Physician_Profile_ID'},inplace=True)\n",
    "sunshine['Prscrbr_NPI']=''\n",
    "sunshine = sunshine[['combined','Prscrbr_NPI','Physician_Profile_ID','fname','lname','type','city']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "part_d.rename(columns={'id':'Prscrbr_NPI'},inplace=True)\n",
    "part_d['Physician_Profile_ID']=''\n",
    "part_d = part_d[['combined','Prscrbr_NPI','Physician_Profile_ID','fname','lname','type','city']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_output = pd.concat([pd.concat([matches,sunshine],ignore_index=True),part_d],ignore_index=True)\n",
    "final_output.drop(columns=['combined'],inplace=True)\n",
    "final_output.reset_index(inplace=True)\n",
    "final_output.rename(columns={'index':'id'},inplace=True)\n",
    "final_output.to_csv('../Data/Physicians_Deduplication/Outputs/Physicians.csv',index=False)\n",
    "final_output.to_pickle('../Data/Physicians_Deduplication/Outputs/Physicians.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
