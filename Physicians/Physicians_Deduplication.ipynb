{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import py_stringmatching as sm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "sunshine = pd.read_csv('../Data/Outputs_Cleanup/Sunshine/physicians_info.csv',dtype=str)\n",
    "sunshine.fillna(value='',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_suffix(lname, suffix):\n",
    "    s = lname + ' ' + suffix\n",
    "    return s.strip()\n",
    "\n",
    "sunshine['Physician_Last_Name'] = sunshine.apply(lambda x: add_suffix(x['Physician_Last_Name'],x['Physician_Name_Suffix']),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "sunshine.rename(columns={'Physician_Profile_ID':'id','Physician_First_Name':'fname','Physician_Specialty':'type',\n",
    "                         'Physician_Last_Name':'lname','Recipient_City':'city'},inplace=True)\n",
    "sunshine.drop(columns=['Physician_Middle_Name','Physician_Name_Suffix','Recipient_State','Physician_Primary_Type',\n",
    "                       'Physician_License_State_code1','Physician_License_State_code2','Physician_License_State_code3',\n",
    "                       'Physician_License_State_code4','Physician_License_State_code5','Recipient_Zip_Code'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "part_d = pd.read_csv('../Data/Outputs_Cleanup/Part_d/prescriber_information.csv',dtype=str)\n",
    "part_d.fillna(value='',inplace=True)\n",
    "part_d.rename(columns={'Prscrbr_NPI':'id','Prscrbr_Last_Org_Name':'lname','Prscrbr_First_Name':'fname',\n",
    "                       'Prscrbr_City':'city','Prscrbr_Type':'type'},inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cities were hand deduped during this first run. However, in the future we will need to make a city deduper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sunshine = pd.read_csv('CMS_Sunshine_Physicians.csv',dtype=str)\n",
    "# part_d = pd.read_csv('Medicare_PartD_Physicians.csv',dtype=str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processType(x):\n",
    "    s = x.split('|')\n",
    "    return s[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processData(df):\n",
    "    cols = df.columns.to_list()\n",
    "    for col in cols:\n",
    "        df[col] = df[col].astype(str)\n",
    "        df[col] = df[col].apply(lambda x: x.lower().strip())\n",
    "    df['type'] = df['type'].apply(lambda x: processType(x))\n",
    "    df['combined'] = df['fname'] + ' ' + df['lname'] + ' ' + df['city'] + ' ' + df['type']\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "sunshine = processData(sunshine)\n",
    "part_d = processData(part_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "sunshine_combined_id = sunshine.groupby('combined')['id'].apply(list).reset_index(name='id')\n",
    "part_d_id = part_d.groupby('combined')['id'].apply(list).reset_index(name='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "sunshine.drop(columns=['id'],inplace=True)\n",
    "part_d.drop(columns=['id'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "sunshine = sunshine.merge(right=sunshine_combined_id,how='left',on='combined')\n",
    "part_d = part_d.merge(right=part_d_id,how='left',on='combined')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "del sunshine_combined_id\n",
    "del part_d_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are duplicates where the same person has two ids in both dataset.<br>\n",
    "The solution is to use the combined column to create a new unique id.<br>\n",
    "Then we will create lookup tables for the new ID and the combined string.<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make the lookup tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sunshine.rename(columns={'id':'Physician_Profile_ID'})[['combined','Physician_Profile_ID']].to_csv('../Data/Physicians_Deduplication/Outputs/CMS_Sunshine_Physicians_NewID.csv',index=False)\n",
    "# part_d.rename(columns={'id':'Prscrbr_NPI'})[['combined','Prscrbr_NPI']].to_csv('../Data/Physicians_Deduplication/Outputs/Medicare_PartD_Physicians_NewID.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "sunshine.drop_duplicates(subset='combined',inplace=True)\n",
    "part_d.drop_duplicates(subset='combined',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "sunshine_org = sunshine.copy()\n",
    "part_d_org = part_d.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we will do a naive matching. Based on just the 'hashID' column. If there is an exact match we will accept this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_part_d = part_d.merge(right=sunshine,on='combined',how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will remove the matches and set them aside. We will do a more careful inspection of the remaining unmatched ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>part_d</th>\n",
       "      <th>sunshine</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [part_d, sunshine]\n",
       "Index: []"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Setting aside matches, keeping pairs together\n",
    "matches = merged_part_d.drop(merged_part_d[(merged_part_d['city_x'].isnull()==True) | (merged_part_d['city_y'].isnull()==True)].index)\n",
    "col = matches.columns.to_list()\n",
    "col.remove('combined')\n",
    "matches.drop(columns = col,inplace=True)\n",
    "matches['combined2'] = matches['combined']\n",
    "matches.rename(columns={'combined':'part_d','combined2':'sunshine'},inplace=True)\n",
    "matches.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "part_d.drop(part_d[part_d['combined'].isin(matches['part_d'].to_list())].index,inplace=True)\n",
    "sunshine.drop(sunshine[sunshine['combined'].isin(matches['sunshine'].to_list())].index,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "del merged_part_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a new column in sunshine that is the combined column whitespace tokenized    \n",
    "#Create a new column in sunshine that is the combined column unigram tokenized\n",
    "#Create a new column in part_d that is the combined column whitespace tokenized\n",
    "#Create a new column in part_d that is the combined column unigram tokenized\n",
    "whitespace_tokenizer = sm.WhitespaceTokenizer()\n",
    "unigram_tokenizer = sm.QgramTokenizer(qval=2)\n",
    "sunshine['whitespace_tok'] = sunshine['combined'].apply(lambda x: whitespace_tokenizer.tokenize(x))\n",
    "sunshine['Qgram_tok'] = sunshine['combined'].apply(lambda x: unigram_tokenizer.tokenize(x))\n",
    "part_d['whitespace_tok'] = part_d['combined'].apply(lambda x: whitespace_tokenizer.tokenize(x))\n",
    "part_d['Qgram_tok'] = part_d['combined'].apply(lambda x: unigram_tokenizer.tokenize(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We will find matches for the sunshine data in the part_d data\n",
    "#This is because the sunshine data is the smaller set\n",
    "#Here is the procedure:    \n",
    "    #For each row in sunshine\n",
    "        #Filter the city in part_d\n",
    "        #Perform Jaccard on the whitespace token set between the remainder and the row\n",
    "        #Filter out for scores higher than .75\n",
    "        #If the remaining dataframe is 0\n",
    "            #Return None\n",
    "        #Else\n",
    "            #Grab the highest matching one as the match\n",
    "            #Save the match into sunshine_match dataframe and part_d_match dataframe\n",
    "        #Remove the row from both part_d_noDups and sunshine_noDups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_measure = sm.OverlapCoefficient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "matched = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_match(sunshine_row):\n",
    "    #filter part_d for the last name:\n",
    "    df_partD = part_d[part_d['lname']==sunshine_row['lname']].copy()\n",
    "    df_partD.drop(df_partD[df_partD['combined'].isin(matched)].index,inplace=True)\n",
    "    if len(df_partD) == 0:\n",
    "        #Return None\n",
    "        return None\n",
    "    #Perform similarity on the token set between the remainder and the row\n",
    "    df_partD['score'] = df_partD['Qgram_tok'].apply(lambda x: sim_measure.get_sim_score(x, sunshine_row['Qgram_tok']))\n",
    "    #Filter out for scores higher than .75\n",
    "    df_partD.drop(df_partD[df_partD['score']<.8].index,inplace=True)\n",
    "    #If the remaining dataframe is 0\n",
    "    if len(df_partD) == 0:\n",
    "        #Return None\n",
    "        return None\n",
    "    #Else if the remaining dataframe is 1\n",
    "    elif len(df_partD) == 1:\n",
    "        #Return the remaining row's hash_id\n",
    "        match = df_partD.iloc[0]['combined']\n",
    "        matched.append(match)\n",
    "        return match\n",
    "    else:\n",
    "        #Sort the remaining rows by score\n",
    "        df_partD.sort_values(by=['score'],axis=0,ascending=False,ignore_index=True,inplace=True)\n",
    "        #Return the highest one\n",
    "        match = df_partD.iloc[0]['combined']\n",
    "        matched.append(match)\n",
    "        return match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\foster\\anaconda3\\lib\\site-packages\\tqdm\\std.py:697: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
      "  from pandas import Panel\n",
      "Progress: 100%|██████████████████████████| 70518/70518 [19:01<00:00, 61.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 19min 1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tqdm.pandas(desc=\"Progress\")\n",
    "sunshine['match'] = sunshine.progress_apply(lambda x: find_match(x),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "other_matches = sunshine[sunshine['match'].isnull()==False][['match','combined']].copy()\n",
    "other_matches.rename(columns={'match':'part_d','combined':'sunshine'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches = pd.concat([matches,other_matches],ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "part_d.drop(part_d[part_d['combined'].isin(matches['part_d'].to_list())].index,inplace=True)\n",
    "sunshine.drop(sunshine[sunshine['combined'].isin(matches['sunshine'].to_list())].index,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "sunshine[['id','fname','lname','type','city']].to_csv('../Data/Physicians_Deduplication/Outputs/CMS_Sunshine_Physicians_no_matches.csv',index=False)\n",
    "part_d[['id','fname','lname','type','city']].to_csv('../Data/Physicians_Deduplication/Outputs/Medicare_PartD_Physicians_no_matches.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches.to_csv('../Data/Physicians_Deduplication/Outputs/Physician_Matches.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "sunshine.drop(columns = ['whitespace_tok','Qgram_tok','match'],inplace=True)\n",
    "part_d.drop(columns = ['whitespace_tok','Qgram_tok'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>part_d</th>\n",
       "      <th>sunshine</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>einat duhamel encinitas obstetrics  gynecology</td>\n",
       "      <td>einat duhamel encinitas allopathic  osteopathi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>erik pasin mission viejo urology</td>\n",
       "      <td>erik pasin mission viejo allopathic  osteopath...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>manilal mehta anaheim urology</td>\n",
       "      <td>manilal mehta anaheim allopathic  osteopathic ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>manmohan gursahani fullerton urology</td>\n",
       "      <td>manmohan gursahani fullerton allopathic  osteo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>helen fincher los angeles dermatology</td>\n",
       "      <td>helen fincher los angeles allopathic  osteopat...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           part_d  \\\n",
       "0  einat duhamel encinitas obstetrics  gynecology   \n",
       "1                erik pasin mission viejo urology   \n",
       "2                   manilal mehta anaheim urology   \n",
       "3            manmohan gursahani fullerton urology   \n",
       "4           helen fincher los angeles dermatology   \n",
       "\n",
       "                                            sunshine  \n",
       "0  einat duhamel encinitas allopathic  osteopathi...  \n",
       "1  erik pasin mission viejo allopathic  osteopath...  \n",
       "2  manilal mehta anaheim allopathic  osteopathic ...  \n",
       "3  manmohan gursahani fullerton allopathic  osteo...  \n",
       "4  helen fincher los angeles allopathic  osteopat...  "
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matches.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches = matches.merge(right = part_d_org,how='left',left_on='part_d',right_on='combined')\n",
    "matches = matches.merge(right = sunshine_org[['combined','id']],how='left',left_on='sunshine',right_on='combined')\n",
    "matches.drop(columns=['part_d','sunshine','combined_y'],inplace=True)\n",
    "matches.rename(columns={'combined_x':'combined','id_x':'Prscrbr_NPI','id_y':'Physician_Profile_ID'},inplace=True)\n",
    "matches = matches[['combined','Prscrbr_NPI','Physician_Profile_ID','fname','lname','type','city']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #matches.rename(columns={'part_d':'id'},inplace=True)\n",
    "# #matches = matches.merge(right = part_d_org,how='left',left_on='id',right_on='combined')\n",
    "# matches.drop(columns=['sunshine','combined'],inplace=True)\n",
    "# matches.rename(columns={'id_x':'combined','id_y':'Prscrbr_NPI'},inplace=True)\n",
    "# matches = matches.merge(right = sunshine_org[['combined','id']],how='left',on='combined')\n",
    "# matches.rename(columns={'id':'Physician_Profile_ID'},inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "sunshine.rename(columns={'id':'Physician_Profile_ID'},inplace=True)\n",
    "sunshine['Prscrbr_NPI']=np.nan\n",
    "sunshine = sunshine[['combined','Prscrbr_NPI','Physician_Profile_ID','fname','lname','type','city']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "part_d.rename(columns={'id':'Prscrbr_NPI'},inplace=True)\n",
    "part_d['Physician_Profile_ID']=np.nan\n",
    "part_d = part_d[['combined','Prscrbr_NPI','Physician_Profile_ID','fname','lname','type','city']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_output = pd.concat([pd.concat([matches,sunshine],ignore_index=True),part_d],ignore_index=True)\n",
    "final_output.drop(columns=['combined'],inplace=True)\n",
    "final_output.reset_index(inplace=True)\n",
    "final_output.rename(columns={'index':'id'},inplace=True)\n",
    "final_output.to_csv('../Data/Physicians_Deduplication/Outputs/Physicians.csv',index=False)\n",
    "final_output.to_pickle('../Data/Physicians_Deduplication/Outputs/Physicians.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
